{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Union, Tuple, NamedTuple\n",
    "from collections import OrderedDict\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data_path =  \"/Volumes/ExFAT/dataset/ml-1m/movies.dat\"\n",
    "user_data_path = \"/Volumes/ExFAT/dataset/ml-1m/users.dat\"\n",
    "ratings_data_path = \"/Volumes/ExFAT/dataset/ml-1m/ratings.dat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns_to_encode: List[str]):\n",
    "        self.columns_to_encode = columns_to_encode\n",
    "        self.unseen = -1\n",
    "\n",
    "    def fit(self, df: pd.DataFrame, y=None):\n",
    "        df_ = df[self.columns_to_encode].copy()\n",
    "\n",
    "        df_[self.columns_to_encode] = df[self.columns_to_encode].astype(\n",
    "            'str')\n",
    "\n",
    "\n",
    "        unique_column_vals = {col: df_[col].unique()\n",
    "                              for col in self.columns_to_encode}\n",
    "\n",
    "        self.encoding_dict_ = OrderedDict()\n",
    "\n",
    "        for col in self.columns_to_encode:\n",
    "            unique_value = unique_column_vals[col]\n",
    "            self.encoding_dict_[col] = {val: idx for idx, val in enumerate(unique_value)}\n",
    "            self.encoding_dict_[col][self.unseen] = len(self.encoding_dict_[col])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, df: pd.DataFrame):\n",
    "        try:\n",
    "            self.encoding_dict_\n",
    "        except AttributeError:\n",
    "            raise NotFittedError(\n",
    "                \"This LabelEncoder instance is not fitted yet. \"\n",
    "                \"Call 'fit' with appropriate arguments before using this LabelEncoder.\"\n",
    "            )\n",
    "        df_ = df.copy()\n",
    "        filtered_columns = [col for col in self.columns_to_encode if col in df_.columns]\n",
    "        df_[filtered_columns] = df_[filtered_columns].astype('str')\n",
    "\n",
    "        for col, encoding_map in self.encoding_dict_.items():\n",
    "            original_value = [f for f in encoding_map.keys() if f != self.unseen]\n",
    "            if col in filtered_columns:\n",
    "                df_[col] = np.where(df_[col].isin(\n",
    "                    original_value), df_[col], self.unseen)\n",
    "                df_[col] = df_[col].apply(lambda x: encoding_map[x])\n",
    "        return df_\n",
    "\n",
    "    \n",
    "class MultiLabelEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns_to_encode: List[str], label_splitter='|'):\n",
    "        self.columns_to_encode = columns_to_encode\n",
    "        self.label_splitter = label_splitter\n",
    "        self.unseen = -1\n",
    "        \n",
    "        \n",
    "    def fit(self, df: pd.DataFrame, y=None):\n",
    "        df_ = df[self.columns_to_encode].copy()\n",
    "       \n",
    "        df_[self.columns_to_encode] = df[self.columns_to_encode].astype(\n",
    "            'str')\n",
    "\n",
    "        \n",
    "        self.encoding_dict_ = OrderedDict()\n",
    "        for col in self.columns_to_encode:\n",
    "            label_2_idx = self._fetch_label2idx_from_column(df_, col)\n",
    "            label_2_idx[self.unseen] = len(label_2_idx)\n",
    "            self.encoding_dict_[col] = label_2_idx\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def _fetch_label2idx_from_column(self, df: pd.DataFrame, col_name: str) -> Dict[str, int]:\n",
    "        all_combination = df[col_name].tolist()\n",
    "        \n",
    "        unique_label = set()\n",
    "        for c in all_combination:\n",
    "            unique_label.update(c.split(self.label_splitter))\n",
    "        \n",
    "        return {label: idx for idx, label in enumerate(unique_label)}\n",
    "        \n",
    "    def transform(self, df: pd.DataFrame):\n",
    "        try:\n",
    "            self.encoding_dict_\n",
    "        except AttributeError:\n",
    "            raise NotFittedError(\n",
    "                \"This LabelEncoder instance is not fitted yet. \"\n",
    "                \"Call 'fit' with appropriate arguments before using this LabelEncoder.\"\n",
    "            )\n",
    "        df_ = df.copy()\n",
    "        df_[self.columns_to_encode] = df_[self.columns_to_encode].astype(str)\n",
    "        \n",
    "        for col, encoding_map in self.encoding_dict_.items():\n",
    "            df_[col] = df_[col].apply(lambda x: self._encoding_fn(encoding_map, x))\n",
    "        \n",
    "        return df_\n",
    "    \n",
    "    def _encoding_fn(self, encoding_map: Dict[str, int], multi_label: str)-> List[int]:\n",
    "        multi_label = multi_label.split(self.label_splitter)\n",
    "        encoded = [encoding_map[i] if i in encoding_map else encoding_map[self.unseen] for i in multi_label]\n",
    "        return encoded\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IDFeaturesGenerator(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, label_cols: List[str], multi_label_cols: List[str]=[]):\n",
    "        self.label_cols = label_cols\n",
    "        self.multi_label_cols = multi_label_cols\n",
    "        self.all_columns = self.label_cols + self.multi_label_cols\n",
    "        \n",
    "    def fit(self, df: pd.DataFrame, y=None):\n",
    "        \n",
    "        df_id = df[self.all_columns].copy()\n",
    "        self.label_encoder_ = LabelEncoder(self.label_cols).fit(df_id)\n",
    "        self.multi_label_encoder_ = MultiLabelEncoder(self.multi_label_cols).fit(df_id)\n",
    "\n",
    "        self.embed_cols_unique_labels_ = OrderedDict()\n",
    "        self.embed_cols_unique_labels_.update({col: len(v) for col, v in self.label_encoder_.encoding_dict_.items()})\n",
    "        self.embed_cols_unique_labels_.update({col: len(v) for col, v in self.multi_label_encoder_.encoding_dict_.items()})\n",
    "    \n",
    "        return self\n",
    "\n",
    "    def transform(self, df: pd.DataFrame)-> pd.DataFrame:\n",
    "        input_columns = df.columns\n",
    "        filtered_columns = [col for col in self.all_columns if col in input_columns]\n",
    "        df_id = df[filtered_columns].copy()\n",
    "        df_id = self.label_encoder_.transform(df_id)\n",
    "        df_id = self.multi_label_encoder_.transform(df_id)\n",
    "        return df_id\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLensDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, user_path: str, movie_path: str, rate_path: str):\n",
    "        self.target_col = 'rating'\n",
    "        self.rating_threshold = 3\n",
    "\n",
    "        self.user_fields = ['userId', 'gender', 'age', 'occupation', 'zipCode']\n",
    "        self.item_fields = ['movieId']\n",
    "\n",
    "        self.all_fields = self.user_fields + self.item_fields\n",
    "        self.fields_index = {col: idx for idx, col in enumerate(self.all_fields)}\n",
    "        \n",
    "        X_df, Y_df = self._get_X_Y(user_path, movie_path, rate_path)\n",
    "        self.X_df = self._X_processing(X_df)\n",
    "        self.Y_df = self._Y_processing(Y_df)\n",
    "        self.X = self.X_df.values  # keep in order\n",
    "        self.Y = self.Y_df.values\n",
    "        \n",
    "        self.fields_dims = self._gen_field_dims()\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.Y.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        return self.X[index], self.Y[index]\n",
    "    \n",
    "    def _get_X_Y(self, user_path: str, movie_path: str, rate_path: str) -> (pd.DataFrame, pd.DataFrame):\n",
    "        user_columns = [\"gender\", \"age\", \"occupation\", \"zipCode\"] \n",
    "        movie_columns = ['title', 'genres']\n",
    "        user_df = pd.read_csv(user_path, sep=\"::\", header=None, engine=\"python\", names=user_columns)\n",
    "        item_df = pd.read_csv(movie_path, sep=\"::\", header=None, engine=\"python\", names=movie_columns).drop('title', axis=1)\n",
    "        rate_df = pd.read_csv(rate_path, sep=\"::\", engine=\"python\", header=None, names=['userId', 'movieId', 'rating', 'timestamp']).drop('timestamp', axis=1) \n",
    "\n",
    "        rate_df = rate_df.merge(user_df, left_on=['userId'], right_index=True, how='inner')\n",
    "        rate_df = rate_df.merge(item_df, left_on=['movieId'], right_index=True, how='inner').reset_index(drop=True)\n",
    "        return rate_df.drop([self.target_col], axis=1), rate_df[[self.target_col]]\n",
    "        \n",
    "\n",
    "    def _X_processing(self, input_df)-> pd.DataFrame:\n",
    "        self.id_feature_encoder_ = IDFeaturesGenerator(label_cols=self.all_fields).fit(input_df)\n",
    "        df_label = self.id_feature_encoder_.transform(input_df)\n",
    "\n",
    "        return df_label[self.all_fields]\n",
    "    \n",
    "    def _Y_processing(self, input_df)-> pd.DataFrame:\n",
    "        target_y = input_df[self.target_col].values.copy()\n",
    "        target_y = (target_y > self.rating_threshold).astype(int)\n",
    "        input_df[self.target_col] = target_y\n",
    "        return input_df\n",
    "    \n",
    "    def _gen_field_dims(self)-> Dict[str, int]:\n",
    "        field_dims = OrderedDict(self.id_feature_encoder_.embed_cols_unique_labels_)\n",
    "        return field_dims\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactorizationMachine(torch.nn.Module):\n",
    "    def __init__(self, reduce_sum=True):\n",
    "        super().__init__()\n",
    "        self.reduce_sum = reduce_sum\n",
    "    \n",
    "    def forward(self, x):\n",
    "        square_of_sum = torch.sum(x, dim=1) ** 2\n",
    "        sum_of_square = torch.sum(x ** 2, dim=1)\n",
    "        ix = square_of_sum - sum_of_square\n",
    "        if self.reduce_sum:\n",
    "            ix = torch.sum(ix, dim=1, keepdim=True) # [b_size, 1]\n",
    "        return 0.5 * ix \n",
    "    \n",
    "class FactorizationMachineModel(torch.nn.Module):\n",
    "    def __init__(self, fields_index: Dict[str, int], fields_dims: Dict[str, int], embed_dim):\n",
    "        super(FactorizationMachineModel, self).__init__()\n",
    "        self.fields_index = fields_index\n",
    "        self.all_fields = [k for k, v in sorted(self.fields_index.items(), key=lambda kv: kv[1])]\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "        self.fields_dims_dict = fields_dims\n",
    "        self.fields_dims = np.array([self.fields_dims_dict[f] for f in self.all_fields])\n",
    "        \n",
    "        self.fields_offset = torch.tensor((0, *np.cumsum(self.fields_dims)[:-1]), dtype=torch.long).requires_grad_(False).unsqueeze(0)\n",
    "        '''\n",
    "            field_offset [1, sum_of_field_dims]\n",
    "            field_dims:  np.array([10, 20 ,5, 7, 9])\n",
    "            [*np.cumsum(self.field_dims)[:-1]] = [10, 30, 35, 42]\n",
    "        '''\n",
    "        self.fields_range = self._gen_fields_range(self.fields_dims)\n",
    "        self.embedding = torch.nn.Embedding(self.fields_dims.sum(), embed_dim)\n",
    "        torch.nn.init.xavier_uniform_(self.embedding.weight.data)\n",
    "        \n",
    "        self.fc = torch.nn.Embedding(self.fields_dims.sum(), 1)\n",
    "        self.bias = torch.nn.Parameter(torch.zeros((1, )))\n",
    "        \n",
    "        self.fm = FactorizationMachine(reduce_sum=True)\n",
    "    \n",
    "    def _forward_embedding(self, X: torch.Tensor):\n",
    "        \n",
    "        return self.embedding(X) # [b_size, field_num, embed_dim]\n",
    "    \n",
    "    def _forward_linear(self, X: torch.Tensor):\n",
    "     \n",
    "        return torch.sum(self.fc(X), dim=1) + self.bias # [b_size, output_dim]\n",
    "        \n",
    "    def get_field_vector(self, field_name: str, label: int)-> np.ndarray:\n",
    "        assert field_name in self.fields_index\n",
    "        assert label < self.fields_dims_dict[field_name]\n",
    "        \n",
    "        field_index = self.fields_index[field_name]\n",
    "        field_range = self.fields_range[field_index]\n",
    "        \n",
    "        field_vector = self.embedding.weight.data[field_range[0]: field_range[1]]\n",
    "        return field_vector[label]\n",
    "\n",
    "    def _gen_fields_range(self, fields_dims: np.ndarray)-> List[Tuple[int, int]]:\n",
    "        fields_offset = [0, *np.cumsum(fields_dims)]\n",
    "        return [(s, e) for s, e in zip(fields_offset, fields_offset[1:])]\n",
    "    \n",
    "\n",
    "    def forward(self, X: torch.Tensor):\n",
    "        # X [b_size, num_fields]\n",
    "        if X.get_device() != self.fields_offset.get_device():\n",
    "            self.fields_offset = self.fields_offset.to(X.device)\n",
    "        \n",
    "        X = X + self.fields_offset\n",
    "        X = self._forward_linear(X) + self.fm(self._forward_embedding(X)) # [b_size, 1]\n",
    "        return X.squeeze(1) # [b_size]\n",
    "\n",
    "    def predict_probs(self, X: torch.Tensor):\n",
    "        with torch.no_grad():\n",
    "            out = self.forward(X)\n",
    "            return torch.sigmoid(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "@torch.no_grad()\n",
    "def cal_metrics(model, X, Y):\n",
    "    model.eval()\n",
    "    y_prob = model.predict_probs(*X)\n",
    "    metrics = _cal_metrics(Y, y_prob)\n",
    "    \n",
    "    model.train()\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def _cal_metrics(Y: torch.Tensor, Y_prob: torch.Tensor):\n",
    "    Y_pre_label = (Y_prob > 0.5).long()\n",
    "    \n",
    "    Y = Y.view(-1).cpu().detach().numpy()\n",
    "    Y_prob = Y_prob.cpu().detach().numpy()\n",
    "    Y_pre_label = Y_pre_label.cpu().detach().numpy()\n",
    "    tn, fp, fn, tp  = confusion_matrix(Y, Y_pre_label).ravel()\n",
    "\n",
    "    precision = (tp) / (tp + fp)\n",
    "    recall = (tp) / (tp + fn)\n",
    "    acc = (tp + tn) / (tn + fp + fn + tp)\n",
    "    \n",
    "    auc = metrics.roc_auc_score(Y, Y_prob)\n",
    "\n",
    "    return {'prec': precision, 'recall': recall, 'acc': acc, 'auc': auc}\n",
    "    \n",
    "\n",
    "@torch.no_grad()\n",
    "def cal_metrics_for_data_loader(model: nn.Module, dataloader):\n",
    "    model.eval()\n",
    "    total_Y = []\n",
    "    total_Y_prob = []\n",
    "    for X, Y in dataloader:\n",
    "        y_prob = model.predict_probs(X)\n",
    "        total_Y.append(Y)\n",
    "        total_Y_prob.append(y_prob)\n",
    "    \n",
    "    total_Y = torch.cat(total_Y, axis=0)\n",
    "    total_Y_prob = torch.cat(total_Y_prob, axis=0)\n",
    "    metrics = _cal_metrics(total_Y, total_Y_prob)\n",
    "    model.train()\n",
    "\n",
    "\n",
    "\n",
    "    return metrics\n",
    "    \n",
    "\n",
    "def validation_step(model: nn.Module, X, Y, loss_fn):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pre = model(X)\n",
    "        loss = loss_fn(y_pre.view(-1).float(), Y.float())  # mean loss\n",
    "    \n",
    "    model.train()\n",
    "    return loss.item(), cal_metrics(model, X, Y)\n",
    "\n",
    "def validation_step_for_data_loader(model: nn.Module, dataloader, loss_fn, device=torch.device('cpu')):\n",
    "    model.eval()\n",
    "    total_Y = []\n",
    "    total_Y_pre = []\n",
    "    with torch.no_grad():\n",
    "        for X, Y in dataloader:\n",
    "            X = X.to(device)\n",
    "            # offset = offset.to(device)\n",
    "            Y = Y.to(device)\n",
    "            y_pre = model(X)\n",
    "            total_Y.append(Y)\n",
    "            total_Y_pre.append(y_pre)\n",
    "            \n",
    "    \n",
    "        Y = torch.cat(total_Y, axis=0)\n",
    "        Y_pre = torch.cat(total_Y_pre, axis=0)\n",
    "\n",
    "        Y_prob = torch.sigmoid(Y_pre)\n",
    "        loss = loss_fn(Y_pre, Y.float().view(-1))\n",
    "        matrics = _cal_metrics(Y, Y_prob)\n",
    "    model.train()\n",
    "    return loss.item(), matrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.6 s, sys: 1.35 s, total: 16.9 s\n",
      "Wall time: 20.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dataset = MovieLensDataset(user_data_path, movie_data_path, ratings_data_path)\n",
    "train_set_size = int(len(dataset) * 0.8)\n",
    "valid_set_size = len(dataset) - train_set_size\n",
    "train_set, valid_set = torch.utils.data.random_split(dataset, [train_set_size, valid_set_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'age': 2,\n",
       "  'gender': 1,\n",
       "  'movieId': 5,\n",
       "  'occupation': 3,\n",
       "  'userId': 0,\n",
       "  'zipCode': 4},\n",
       " OrderedDict([('userId', 6041),\n",
       "              ('gender', 3),\n",
       "              ('age', 8),\n",
       "              ('occupation', 22),\n",
       "              ('zipCode', 3440),\n",
       "              ('movieId', 3707)]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.fields_index, dataset.fields_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_interval = 500\n",
    "epoch = 5\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = 50\n",
    "fields_index = dataset.fields_index\n",
    "fields_dims = dataset.fields_dims\n",
    "fm_model = FactorizationMachineModel(fields_index, fields_dims, dims)\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='mean')\n",
    "optimizer = torch.optim.AdamW(params=fm_model.parameters(), lr=0.001, weight_decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2668/2668 [01:15<00:00, 35.29it/s, metrics={'prec': 0.7313, 'recall': 0.7909, 'acc': 0.7125, 'auc': 0.7744}, train_loss=0.568, valid_loss=0.564]\n",
      "100%|██████████| 2668/2668 [01:26<00:00, 30.98it/s, metrics={'prec': 0.7367, 'recall': 0.7872, 'acc': 0.7157, 'auc': 0.7792}, train_loss=0.556, valid_loss=0.559]\n",
      "100%|██████████| 2668/2668 [01:24<00:00, 31.46it/s, metrics={'prec': 0.7368, 'recall': 0.8012, 'acc': 0.721, 'auc': 0.7857}, train_loss=0.546, valid_loss=0.552]\n",
      "100%|██████████| 2668/2668 [01:11<00:00, 37.38it/s, metrics={'prec': 0.7455, 'recall': 0.7913, 'acc': 0.7245, 'auc': 0.7899}, train_loss=0.538, valid_loss=0.546]\n",
      "100%|██████████| 2668/2668 [01:32<00:00, 28.93it/s, metrics={'prec': 0.7458, 'recall': 0.8, 'acc': 0.7281, 'auc': 0.7945}, train_loss=0.522, valid_loss=0.542]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fm_model = fm_model.to(device)\n",
    "train_data_loader = torch.utils.data.DataLoader(train_set, batch_size=300, shuffle=True)\n",
    "valid_data_loader = torch.utils.data.DataLoader(valid_set, batch_size=300, shuffle=False)\n",
    "\n",
    "count = 0\n",
    "for epoch_i in range(epoch):\n",
    "    total_loss = 0\n",
    "    # tk0 = tqdm.tqdm(train_data_loader, smoothing=0, mininterval=1.0)\n",
    "    tk0 = tqdm.tqdm(train_data_loader, smoothing=0, mininterval=1.0, position=0, leave=True)\n",
    "    for i, (X, Y) in enumerate(tk0):\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "        fm_model.train()\n",
    "        y_pre = fm_model(X)\n",
    "        loss = criterion(y_pre.view(-1), Y.float().view(-1))\n",
    "        \n",
    "        fm_model.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "     \n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        count += 1\n",
    "        if (count) % log_interval == 0:\n",
    "            valid_loss, score = validation_step_for_data_loader(fm_model, valid_data_loader, criterion, device)\n",
    "            tk0.set_postfix(train_loss=total_loss/log_interval, valid_loss=valid_loss, metrics={k: np.round(v, 4) for k, v in score.items()})\n",
    "            total_loss = 0\n",
    "            count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5396221280097961,\n",
       " {'acc': 0.7284720208756161,\n",
       "  'auc': 0.7961434666838393,\n",
       "  'prec': 0.7469499557022214,\n",
       "  'recall': 0.7985436471385621})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_step_for_data_loader(fm_model, valid_data_loader, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item Embedding & User Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "ID2Vector = namedtuple('id2vector', 'id vector')\n",
    "class FMEmbedding:\n",
    "    def __init__(self, id_encoder, user_fields, item_fields, fm_model):\n",
    "        self.id_encoder = id_encoder\n",
    "        self.user_fields = user_fields\n",
    "        self.item_fields = item_fields\n",
    "        self.fm_model = fm_model\n",
    "        \n",
    "        self.fields_dims_dict = fm_model.fields_dims_dict\n",
    "        self.fields_index=  fm_model.fields_index\n",
    "        self.fields_dims = fm_model.fields_dims\n",
    "        self.fields_range = self._gen_fields_range(self.fields_dims)\n",
    "        \n",
    "        \n",
    "        self.fields_vectors = self.fm_model.embedding.weight.data.numpy() # hidden vector\n",
    "        self.fields_weights = self.fm_model.fc.weight.data.numpy()\n",
    "        self.bias = self.fm_model.bias.data.numpy()\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    def get_user_embedding(self, primitive_features: pd.DataFrame, userId_column='userId')-> List[ID2Vector]:\n",
    "        assert set(primitive_features.columns) == set(self.user_fields)\n",
    "        user_id_features = self.id_encoder.transform(primitive_features).values\n",
    "        user_fields_index = [self.fields_index[col] for col in self.user_fields]\n",
    "        \n",
    "        fields_offset = np.array([0, *np.cumsum(self.fields_dims)[:-1]])[user_fields_index].reshape((1, -1))\n",
    "        user_IDs_features = user_id_features + fields_offset\n",
    "        \n",
    "    \n",
    "      \n",
    "        '''  field vector'''\n",
    "        user_IDs_vectors = np.take(self.fields_vectors, user_IDs_features, axis=0) # [b_size, user_field_size, vector_dims]\n",
    "        user_fields_cross = self._cross_vector(user_IDs_vectors) # [b_size]\n",
    "        \n",
    "        user_IDs_vectors = user_IDs_vectors.sum(axis=1) # [b_size, vector_dims]\n",
    "\n",
    "        \n",
    "        '''field weight'''\n",
    "        user_fields_weights = np.take(self.fields_weights, user_IDs_features, axis=0).squeeze(2) # [b_size, user_field_size]\n",
    "        user_fields_weights = user_fields_weights.sum(axis=1) # [b_size]\n",
    "\n",
    "       \n",
    "        \n",
    "        '''\n",
    "            user embebding composition [1 :: (user_fields_cross + user_fields_weghts):: user_IDs_vectors]\n",
    "        '''\n",
    "        ones = np.ones((len(user_fields_weights), 1)) # [b_size]\n",
    "        \n",
    "        embedding =  np.hstack([ones, np.expand_dims(user_fields_cross + user_fields_weights, 1), user_IDs_vectors])\n",
    "\n",
    "        id2vector = [ID2Vector(userId, vector) for userId, vector in zip(primitive_features[userId_column].tolist(), embedding)]\n",
    "        return id2vector\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "    def get_item_embedding(self, primitive_features: pd.DataFrame, itemId_col='itemId')-> List[ID2Vector]:\n",
    "        assert set(primitive_features.columns) == set(self.item_fields)\n",
    "        '''\n",
    "            primitive_features may contain unseen itemId\n",
    "        '''\n",
    "        item_id_feautres = self.id_encoder.transform(primitive_features).values\n",
    "        item_fields_index = [self.fields_index[col] for col in self.item_fields]\n",
    "        \n",
    "        fields_offset = np.array([0, *np.cumsum(self.fields_dims)[:-1]])[item_fields_index].reshape((1, -1))\n",
    "        \n",
    "        item_IDs_features = item_id_feautres + fields_offset\n",
    "        \n",
    "        ''' field vector '''\n",
    "        item_IDs_vectors = np.take(self.fields_vectors, item_IDs_features, axis=0) # [b_size, item_fields_size, field_vector_dims]\n",
    "        item_fields_cross = self._cross_vector(item_IDs_vectors) # [b_size]\n",
    "        item_IDs_vectors = item_IDs_vectors.sum(axis=1) # [b_size, field_vector_dims]\n",
    "        \n",
    "        '''field weight'''\n",
    "        item_fields_weights = np.take(self.fields_weights, item_IDs_features, axis=0).squeeze(2) # [b_size, item_field_size]\n",
    "        item_fields_weights = item_fields_weights.sum(axis=1) # [b_size]\n",
    "    \n",
    "#         '''bias'''\n",
    "#         bias = np.full((len(item_fields_weights), 1), self.bias.data)\n",
    "        \n",
    "        '''\n",
    "            item embedding composition: [(item_fields_weights + item_fileds_cross ):: 1 :: item field vector]\n",
    "    \n",
    "        '''\n",
    "        ones = np.ones((len(item_fields_weights), 1)) # [b_size, 1]\n",
    "        sum_ = np.expand_dims(item_fields_weights + item_fields_cross, 1)\n",
    "\n",
    "        \n",
    "        embedding = np.hstack([sum_, ones, item_IDs_vectors])\n",
    "        id2vector = [ID2Vector(itemId, vector) for itemId, vector in zip(primitive_features[itemId_col].tolist(), embedding) ]\n",
    "        return id2vector\n",
    "    \n",
    "    def _l2_norm(self, vectors: np.ndarray)-> np.ndarray:\n",
    "        l2norm = np.linalg.norm(vectors, 2, axis=1, keepdims=True) # [b_size, 1]\n",
    "        return vectors / l2norm\n",
    "    \n",
    "    def _cross_vector(self, vectors: np.ndarray)-> int:\n",
    "        '''\n",
    "            @vectors: [b_size, vector_dims]\n",
    "        '''\n",
    "        square_of_sum = np.sum(vectors, axis=1) ** 2\n",
    "        sum_of_square = np.sum(vectors ** 2, axis=1)\n",
    "        reduce_sum = np.sum(square_of_sum - sum_of_square, axis=1) # [b_size, 1]\n",
    "        return 0.5 * reduce_sum\n",
    "        \n",
    "    def _get_field_vector(self, field_name: str, label: int)-> np.ndarray:\n",
    "        assert field_name in self.fields_index\n",
    "        assert label < self.fields_dims_dict[field_name]\n",
    "        \n",
    "        field_index = self.fields_index[field_name]\n",
    "        field_range = self.fields_range[field_index]\n",
    "        \n",
    "        field_vector = self.fields_vectors[field_range[0]: field_range[1]]\n",
    "        \n",
    "        return field_vector[label]\n",
    "\n",
    "        \n",
    "    \n",
    "    def _gen_fields_range(self, fields_dims: np.ndarray)-> List[Tuple[int, int]]:\n",
    "        fields_offset = [0, *np.cumsum(fields_dims)]\n",
    "        return [(s, e) for s, e in zip(fields_offset, fields_offset[1:])]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_columns = [\"gender\", \"age\", \"occupation\", \"zipCode\"] \n",
    "movie_columns = ['title', 'genres']\n",
    "user_df = pd.read_csv(user_data_path, sep=\"::\", header=None, engine=\"python\", names=user_columns)\n",
    "item_df = pd.read_csv(movie_data_path, sep=\"::\", header=None, engine=\"python\", names=movie_columns).drop('title', axis=1)\n",
    "item_df = item_df.reset_index().rename({'index': 'movieId'}, axis=1)[['movieId']]\n",
    "\n",
    "user_df = user_df.reset_index().rename({'index': 'userId'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3883, 6040)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_encoder = dataset.id_feature_encoder_\n",
    "user_field = dataset.user_fields\n",
    "item_field = dataset.item_fields\n",
    "\n",
    "fm_embedding = FMEmbedding(id_encoder, user_field, item_field, fm_model)\n",
    "\n",
    "item_id_2_vector = fm_embedding.get_item_embedding(item_df, 'movieId')\n",
    "user_id_2_vector = fm_embedding.get_user_embedding(user_df, 'userId')\n",
    "\n",
    "len(item_id_2_vector), len(user_id_2_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id2vector(id=1, vector=array([ 1.        ,  1.57251287,  0.31802261, -0.05311833, -0.51956671,\n",
       "       -0.41219246, -0.24985576, -0.65933889,  0.59215838,  0.41595197,\n",
       "        0.11497089, -0.69019455,  0.24329846,  0.45048714, -0.05286196,\n",
       "        0.2054476 ,  0.30616254,  0.30125472,  0.40432882,  0.26946735,\n",
       "       -0.28497586,  0.23863903,  0.37228948, -0.47429329, -0.21513283,\n",
       "       -0.37172595, -0.29311907,  0.32599026, -0.37352464, -0.65939361,\n",
       "       -0.13792202, -0.29631072, -0.70424175, -0.03108542, -0.47497728,\n",
       "        0.65669644, -0.0536177 , -0.46591866,  0.04575365, -0.47661048,\n",
       "       -0.23746635, -0.48891699, -0.39626658,  0.34011322,  0.42570654,\n",
       "       -0.53802925, -0.32868454,  0.31107759,  0.65648586,  0.36503255,\n",
       "        0.22789076,  0.56083   ]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id_2_vector[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id2vector(id=1, vector=array([-1.6513232 ,  1.        , -0.15136771, -0.19989893, -0.17711505,\n",
      "       -0.27605495, -0.17580783, -0.20358004,  0.19178246,  0.28852561,\n",
      "        0.19627182, -0.21493186,  0.22243072,  0.24396233, -0.17809424,\n",
      "        0.19624405,  0.21878579,  0.20799968,  0.12430456,  0.18400647,\n",
      "       -0.18915175,  0.17806746,  0.21123466, -0.15553948, -0.20221886,\n",
      "       -0.23133394, -0.19063245,  0.25346702, -0.19234048, -0.20784694,\n",
      "       -0.12557872, -0.25455537, -0.15617739, -0.22168253, -0.14932276,\n",
      "        0.25438485,  0.19298089, -0.23894864, -0.26424453, -0.18523659,\n",
      "        0.20755866, -0.17146595, -0.1505574 ,  0.26266149,  0.12615746,\n",
      "       -0.16710922, -0.19842891,  0.20556726,  0.16274993,  0.14940131,\n",
      "        0.16785385,  0.24925581]))\n"
     ]
    }
   ],
   "source": [
    "item_id_2_vector[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task\n",
    "* I2I match\n",
    "* U2I match\n",
    "* coarse ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorProvider:\n",
    "    def __init__(self, id2vector: ID2Vector):\n",
    "        self.ID2Vector = {id_: vec for id_, vec in id2vector}\n",
    "    \n",
    "    def __getitem__(self, id_):\n",
    "        return self.ID2Vector[id_]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ID2Vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I2I  match\n",
    "we could match item by item embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "offline:\n",
    "    push embedding into faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_item_id, item_embedding = zip(*item_id_2_vector)\n",
    "all_item_id = np.array(all_item_id)\n",
    "item_embedding = np.array(item_embedding)\n",
    "movie_embedding_faiss_index = faiss.IndexFlatIP(item_embedding.shape[1])\n",
    "movie_id_faiss_index = faiss.IndexIDMap(movie_embedding_faiss_index)\n",
    "movie_id_faiss_index.add_with_ids(item_embedding.astype('float32'), np.array(all_item_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### online match\n",
    "match I2I online with faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_vector_provider = VectorProvider(item_id_2_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 52)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "online\n",
    "    fetch movie ids and their corresponding vectors which user have interacted\n",
    "'''\n",
    "user_seen_movie_id = [10 , 20, 50, 70]\n",
    "vectors = np.array([item_vector_provider[id_] for id_ in user_seen_movie_id])\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 20), (4, 20))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "each_match_num = 20\n",
    "sim_score, movie_ids = movie_id_faiss_index.search(vectors.astype('float32'), each_match_num)\n",
    "sim_score.shape, movie_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 810, 2818, 3667, 1322, 3564, 2449, 1826, 2298, 1520, 2368, 2383,\n",
       "       1324, 1853, 3042, 1328, 3041, 2534,  470,  460, 3463, 2818, 3458,\n",
       "       3463, 3778, 1764, 3772, 3945, 2982,  240, 1538, 1714, 2974, 1011,\n",
       "        393, 1983,  853, 1760, 3534, 3440, 1556, 2562, 3359, 1262, 2819,\n",
       "        475, 1910, 1206, 2503, 3281, 2731,  265,  551,  527,  722,  326,\n",
       "        853, 1268,  746, 1250, 1188, 3778, 2562,  853,  240, 1983, 1910,\n",
       "        551, 3534, 1268, 3458, 1058, 2299, 3359,  475, 1206, 1730, 2819,\n",
       "       1764,  722, 1011])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_ids.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### offline match\n",
    "we could compute all i2i offline, and store I2I in redis or other DB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3883, 30), (3883, 30))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "each_match_num = 30\n",
    "sim_score, match_movie_ids = movie_id_faiss_index.search(item_embedding.astype('float32'), each_match_num)\n",
    "sim_score.shape, match_movie_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_2_I = []\n",
    "for trigger_id, match_ids, match_scores in zip(all_item_id, match_movie_ids, sim_score):\n",
    "    k2i = {}\n",
    "    k2i['trigger_key'] = trigger_id\n",
    "    pairs = [{'key':id_, 'score': s } for id_, s in zip(match_ids, match_scores) if i != trigger_id]\n",
    "    k2i['pairs'] = pairs\n",
    "    key_2_I.append(k2i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pairs': [{'key': 2562, 'score': 8.487403},\n",
       "  {'key': 3359, 'score': 7.370528},\n",
       "  {'key': 853, 'score': 7.3140664},\n",
       "  {'key': 1910, 'score': 7.243814},\n",
       "  {'key': 3778, 'score': 7.064466},\n",
       "  {'key': 2819, 'score': 6.9514284},\n",
       "  {'key': 475, 'score': 6.9262433},\n",
       "  {'key': 551, 'score': 6.886018},\n",
       "  {'key': 1262, 'score': 6.7728105},\n",
       "  {'key': 1206, 'score': 6.7252},\n",
       "  {'key': 1268, 'score': 6.680213},\n",
       "  {'key': 265, 'score': 6.674436},\n",
       "  {'key': 722, 'score': 6.644379},\n",
       "  {'key': 3281, 'score': 6.6103525},\n",
       "  {'key': 2299, 'score': 6.536831},\n",
       "  {'key': 1983, 'score': 6.5208454},\n",
       "  {'key': 1188, 'score': 6.499143},\n",
       "  {'key': 1730, 'score': 6.414803},\n",
       "  {'key': 240, 'score': 6.3780065},\n",
       "  {'key': 2757, 'score': 6.29891},\n",
       "  {'key': 2731, 'score': 6.23072},\n",
       "  {'key': 3534, 'score': 6.217514},\n",
       "  {'key': 746, 'score': 6.1960998},\n",
       "  {'key': 326, 'score': 6.194806},\n",
       "  {'key': 3296, 'score': 6.143187},\n",
       "  {'key': 1058, 'score': 6.070843},\n",
       "  {'key': 2503, 'score': 6.015757},\n",
       "  {'key': 1187, 'score': 5.9964414},\n",
       "  {'key': 1218, 'score': 5.899559},\n",
       "  {'key': 2782, 'score': 5.8903465}],\n",
       " 'trigger_key': 1}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    now, we have each items' match. we could push them into low latency/RT DB such as Radis\n",
    "'''\n",
    "print(len(key_2_I))\n",
    "key_2_I[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U2I match\n",
    "we could match items by user embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Offline\n",
    "      push item embedding into faiss\n",
    "'''\n",
    "all_item_id, item_embedding = zip(*item_id_2_vector)\n",
    "all_item_id = np.array(all_item_id)\n",
    "item_embedding = np.array(item_embedding)\n",
    "movie_embedding_faiss_index = faiss.IndexFlatIP(item_embedding.shape[1])\n",
    "movie_id_faiss_index = faiss.IndexIDMap(movie_embedding_faiss_index)\n",
    "movie_id_faiss_index.add_with_ids(item_embedding.astype('float32'), np.array(all_item_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Offline\n",
    "        push user embedding into faiss\n",
    "'''\n",
    "all_user_id, user_embedding = zip(*user_id_2_vector)\n",
    "all_user_id = np.array(all_user_id)\n",
    "user_embedding = np.array(user_embedding)\n",
    "user_embedding_faiss_index = faiss.IndexFlatIP(user_embedding.shape[1])\n",
    "user_id_faiss_index = faiss.IndexIDMap(user_embedding_faiss_index)\n",
    "user_id_faiss_index.add_with_ids(user_embedding.astype('float32'), np.array(all_user_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  0.39185381,  0.19535223, -0.20054442, -0.20946348,\n",
       "       -0.36996123, -0.08126716, -0.44307205,  0.22863899, -0.03199186,\n",
       "        0.17294753, -0.19460428,  0.16487858,  0.34271821, -0.35793361,\n",
       "       -0.02658781, -0.00436664,  0.20797843,  0.02937129, -0.06523762,\n",
       "       -0.1621742 , -0.12532774,  0.2529372 , -0.21797934, -0.20383394,\n",
       "       -0.20071481, -0.32262015,  0.16958363, -0.02863088, -0.04059249,\n",
       "       -0.18969983, -0.3594957 , -0.54900992, -0.18492299, -0.0788543 ,\n",
       "       -0.09508141, -0.07884572,  0.12967639, -0.30631033, -0.3674185 ,\n",
       "       -0.1241807 , -0.18993324,  0.07831126,  0.23598528,  0.12474939,\n",
       "       -0.23666811, -0.11751484,  0.0548125 ,  0.21935403,  0.07483938,\n",
       "        0.02026522, -0.4154602 ])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Online\n",
    "        fetch user embedding first\n",
    "'''\n",
    "user_vector_provider = VectorProvider(user_id_2_vector)\n",
    "query_user_id = 500\n",
    "u_embedding = user_vector_provider[query_user_id]\n",
    "u_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[4.173138 , 3.2012074, 3.1826928, 3.0340588, 2.753229 , 2.7324831,\n",
       "         2.664315 , 2.6517272, 2.6254842, 2.6195984, 2.5988796, 2.5158465,\n",
       "         2.511135 , 2.4963562, 2.4919398, 2.4910007, 2.4246888, 2.409114 ,\n",
       "         2.3496847, 2.3489919]], dtype=float32),\n",
       " array([[3460,  545, 1249, 2839, 1086, 3888,  758, 2243, 2584, 1235, 3542,\n",
       "         3547,   73, 3647, 2309,  868, 1934, 1471, 3140, 1002]]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    excute u2i\n",
    "'''\n",
    "topk = 20\n",
    "sim_scores, match_movie_ids = movie_id_faiss_index.search(np.expand_dims(u_embedding.astype('float32'), 0), topk)\n",
    "''' now we have socre and match item ids'''\n",
    "sim_scores, match_movie_ids "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank task\n",
    "if we have tons of match items from different match methods such as C2I, contentI2I, SwingI2I ..., we may need a coarse rank before sending these huge amount of items into fine rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(input_: np.ndarray):\n",
    "    return 1 / ( 1 + np.exp(-input_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    online vector provider\n",
    "'''\n",
    "item_vector_provider = VectorProvider(item_id_2_vector)\n",
    "user_vector_provider = VectorProvider(user_id_2_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, array([2050, 2211, 3185, 2229, 2209, 1596,  702, 2365, 1055, 1648, 3004,\n",
       "         115, 2738, 3064, 1339,  975,  969, 3935, 1892, 2269,  759, 3348,\n",
       "        2523, 2908, 1233, 1819, 3604, 1731, 2546,  111, 3287, 1855, 2507,\n",
       "        1394, 2937,  618, 1032, 1366, 1207,  246, 1180, 1776, 2745,  717,\n",
       "        2421, 3203,  356,  870, 3888, 1930,   93, 3900, 1340, 3431, 2167,\n",
       "        1441, 3261, 2157, 3465, 3094, 1608,  562, 2401,  790, 3226,  338,\n",
       "        2272, 2980, 3610,  656, 2031, 2719,  950, 1490, 3570, 1980,  270,\n",
       "        3082, 2814, 3645,  621, 3147,   20,  835, 1997,  621, 3490, 2082,\n",
       "        1244,  518]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    suppost we have the following match items from different methods\n",
    "'''\n",
    "uid = 1000\n",
    "match_from_A = np.random.choice(np.array(list(item_vector_provider.ID2Vector.keys())), size=30)\n",
    "match_from_B = np.random.choice(np.array(list(item_vector_provider.ID2Vector.keys())),  size=30)\n",
    "match_from_C = np.random.choice(np.array(list(item_vector_provider.ID2Vector.keys())), size=30)\n",
    "all_match = np.hstack([match_from_A, match_from_B, match_from_C])\n",
    "len(all_match), all_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((52,), (90, 52))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    we need their vector to compute similairty score\n",
    "'''\n",
    "u_vector = user_vector_provider[uid]\n",
    "i_vectors = np.array([item_vector_provider[movie_id] for movie_id in all_match])\n",
    "u_vector.shape, i_vectors.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33590833, 0.86267896, 0.54783987, 0.39107268, 0.60883679,\n",
       "       0.75336175, 0.79866159, 0.33833122, 0.34040079, 0.85555893,\n",
       "       0.26738468, 0.39107268, 0.75699356, 0.28491491, 0.602693  ,\n",
       "       0.3113216 , 0.95712211, 0.33731565, 0.69468696, 0.27277618,\n",
       "       0.91938752, 0.39107268, 0.18719235, 0.91121389, 0.96071996,\n",
       "       0.39107268, 0.7464813 , 0.08801003, 0.35710347, 0.93656007,\n",
       "       0.3688742 , 0.28884342, 0.61531689, 0.88622646, 0.90222217,\n",
       "       0.15696627, 0.77505876, 0.66975122, 0.98230138, 0.96528168,\n",
       "       0.92719865, 0.39107268, 0.84378158, 0.79882062, 0.20848772,\n",
       "       0.86573958, 0.89256964, 0.18088923, 0.98779076, 0.95272191,\n",
       "       0.24272658, 0.73399055, 0.83591797, 0.37842401, 0.58474354,\n",
       "       0.77333044, 0.7288076 , 0.69604849, 0.27603054, 0.80239154,\n",
       "       0.72072302, 0.86574538, 0.76624671, 0.09432834, 0.39107268,\n",
       "       0.38262288, 0.76975123, 0.39107268, 0.12335406, 0.32328629,\n",
       "       0.32221952, 0.159449  , 0.96235551, 0.05106423, 0.64326881,\n",
       "       0.12200829, 0.53352518, 0.48059579, 0.07330205, 0.71990685,\n",
       "       0.84499138, 0.93766716, 0.18268432, 0.62423842, 0.78064568,\n",
       "       0.84499138, 0.34813066, 0.40471958, 0.90342323, 0.36655309])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    compute the probability of the userId liking these movies\n",
    "'''\n",
    "scores = np.dot(i_vectors, u_vector)\n",
    "predicted_prob = sigmoid(scores)\n",
    "predicted_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    If we only need the order of movies, \n",
    "    we don't neet to compute sigmoid which is time consuming\n",
    "'''\n",
    "\n",
    "(all_match[np.argsort(predicted_prob)[::-1]] == all_match[np.argsort(scores)[::-1]]).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_i = i_vectors[0][2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.37054822,  0.13287237,  0.06564476,  0.07536279,  0.17927961,\n",
       "        0.10481395, -0.02779581, -0.08033053, -0.1240812 ,  0.08976817,\n",
       "       -0.16599716, -0.13023286,  0.10579411, -0.1032544 , -0.14951137,\n",
       "       -0.18511195, -0.17597082, -0.20446178,  0.1293332 , -0.22905825,\n",
       "       -0.08866128,  0.12667163,  0.11225216,  0.05634275,  0.16195573,\n",
       "       -0.14689794,  0.16846056,  0.10221358,  0.18979949,  0.10170981,\n",
       "        0.05192529,  0.13978741,  0.25230175, -0.08643388, -0.09486112,\n",
       "        0.13592705,  0.1512354 ,  0.11873481, -0.15848108,  0.11546322,\n",
       "        0.12418077, -0.10911771, -0.13562456,  0.11305237,  0.11150885,\n",
       "       -0.12580965, -0.14510785, -0.19855882, -0.12131623, -0.18957341])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
